{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pubmed Data Ingestion\n",
    "\n",
    "This notebook handles the ingestion of raw data from the Pubmed FTP server csv file(s)"
   ],
   "id": "4e32370f973dd76e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "import gzip\n",
    "import tempfile\n",
    "from ftplib import FTP\n",
    "import logging\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Setup Python logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# FTP file functions\n",
    "def pubmed_ftp_client():\n",
    "    ftp = FTP('ftp.ncbi.nlm.nih.gov')\n",
    "    ftp.login()\n",
    "    ftp.cwd('/pubmed/updatefiles/')\n",
    "    return ftp\n",
    "\n",
    "def retrieve_file(ftp_client, filename):\n",
    "    local_filename = tempfile.mkstemp()[1]\n",
    "\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        ftp_client.retrbinary(f'RETR {filename}', f.write)\n",
    "\n",
    "    logger.info(f'Retrieved {filename} as {local_filename}')\n",
    "    return local_filename"
   ],
   "id": "212795db799f79c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_xml_content(xml_gz_filename):\n",
    "    with gzip.open(xml_gz_filename, \"rb\") as xml_file:\n",
    "        return xml_file.read().decode()"
   ],
   "id": "3906552a46f0e74d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Function to fetch raw Pubmed data",
   "id": "8fd57f6ad19c74c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fetch_raw_pubmed_data():\n",
    "    ftp = pubmed_ftp_client()\n",
    "    remote_filenames = sorted([f for f in ftp.nlst() if f.endswith('.xml.gz')])\n",
    "    \n",
    "    for fname in remote_filenames[:10]:\n",
    "        local_fname = retrieve_file(ftp, fname)\n",
    "        xml_content = get_xml_content(local_fname)\n",
    "        yield fname, xml_content"
   ],
   "id": "730c1f77426cc014"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define table for raw Pubmed data",
   "id": "7939fffaa6e226bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dlt.table(\n",
    "    comment=\"Raw Pubmed works data\",\n",
    "    table_properties={\"quality\": \"bronze\"}\n",
    ")\n",
    "def pubmed_ingestion():\n",
    "    raw_data_schema = StructType([\n",
    "        StructField(\"pubmed_fname\", StringType(), True),\n",
    "        StructField(\"xml_content\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    df = spark.createDataFrame(fetch_raw_pubmed_data(), schema=raw_data_schema) \\\n",
    "           .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    \n",
    "    logger.info(f\"Raw data ingestion complete. Total rows: {df.count()}\")\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ],
   "id": "b2e594014d7d9ded"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
